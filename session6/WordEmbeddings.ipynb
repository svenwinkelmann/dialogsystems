{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordEmbeddings\n",
    "\n",
    "Ziele der heutigen Übung:\n",
    "- WordEmbeddins anwenden\n",
    "- Semantic Similarity berechnen können"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein guter Artikel für diese Übung ist: https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/  Lese ihn durch und wende ihn für diese Übung an.\n",
    "\n",
    "Installiere als erstes die beiden Bibliotheken ```nltk```und ```gensim```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir möchten in der heutigen Übung ein Modell von WordEmbeddings auf Basis eines eigenen Textes generieren. Der Text sollte eine gewisse Länge haben, ein Buch ist nicht verkehrt. Freie Bücher findet man zum Beispiel auf https://www.gutenberg.org/\n",
    "\n",
    "Lade den Text aus dem entsprechenden File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing und explorative Datenanalyse ist nie verkehrt, denn auf Basis eines schlechten, ungepflegten Datensatzes kann kein gutes Modell trainiert werden. Ersetze auf jeden Fall Zeilenumbrüche durch Leerzeichen. Je nach Buch sind eventuell auch weitere Anpassungen notwendig. Du solltest danach einen fortlaufenden Text haben. Es empfiehlt sich auch einige Statistiken über den Text auszugeben, um ein Gefühl für dessen Eigenschaften zu bekommen (z.B. Satz-, Wort-, Characteranzahl).Die NLTK Bibliothek hat dafür  einige praktischen Funktionen, die wir nun nutzen möchten. Recherchiere hierzu in der API, welche Funktionen sinnvoll sind:: https://www.nltk.org/api/nltk.tokenize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo\n",
    "\n",
    "print(\"Dataset Exploration:\")\n",
    "print(\"\\tNumber of characters: \")\n",
    "print(\"\\tNumber of words: \")\n",
    "print(\"\\tNumber of sentences: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nutze nun ```gensim.models.Word2Vec``` um ein CBOW und ein SkipGram WordEmbedding-Modell aus deinem Text zu erstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schau dir bei beiden Modellen einige WordEmbeddings an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Vorlesung haben wir die Ähnlichkeit von Wörtern mit der Kosinus-Ähnlichkeit zwischen zwei WordEmbedding Vektoren berechnet. Nutze die Formel um zwischen zwei Vektoren die Ähnlichkeit zu bestimmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "#todo\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nutze nun die ```similarity``` Funktion, ist das Ergebnis gleich deiner eigenen Berechnung? Woran könnte der Unterschied liegen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessant ist die Funktion ```most_similar``` lese dir die Doku durch und probiere einige Wörter deines Buches aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
