{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 1.5: Pizza Service Dialoge (Taskmaster-1, übersetzt für EMNLP 2020)\n",
    "\n",
    "Dataset from M Amin Farajian, António V Lopes, André FT Martins, Sameen Maruf, Gholamreza Haffari (2020). Findings of the wmt 2020 shared task on chat translation (https://aclanthology.org/2020.wmt-1.3/)\n",
    "\n",
    "Wir bekommen den Auftrag ein Dialogsystem für einen Pizza Service zu erstellen, um automatisiert Anfragen bearbeiten zu können. Nun stellt sich die gute Frage: wie reden die Menschen in einem entsprechenden Dialog? Ein guter Ansatz ist zuerst bestehende Dialoge anzuschauen und Herausforderungen (wie z.B anaphorische Referenzen) zu identifizieren.\n",
    "\n",
    "Ziele der heutigen Übung:\n",
    "- Einen bestehenden Datensatz runterladen\n",
    "- Dialoge analysieren und verstehen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorverarbeitung des Datensatzes\n",
    "\n",
    "Um zu wissen womit wir es zu tun haben, lesen wir zuerst den Abstract des Papers (Farajian, 2020) und die README des GitHub Repos: https://github.com/Unbabel/BConTrasT\n",
    "\n",
    "\n",
    "Zuerst laden wir den Datensatz mit git herunter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/Unbabel/BConTrasT ../data/BConTrasT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir mit dem Datensatz nichts trainieren möchten, benötigen wir kein train-test split, sondern laden uns alle vorhandenen Dialoge in ein pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_FOLDER = f'..{os.path.sep}data{os.path.sep}BConTrasT'\n",
    "DATASET_FILES = ['train.json', 'dev.json', 'test1_corpus-with_gold_references.json']\n",
    "\n",
    "dict_dataset = {}\n",
    "for ds_file in DATASET_FILES:\n",
    "    with open(os.path.join(DATASET_FOLDER, ds_file), encoding=\"utf-8\") as file:\n",
    "        dict_dataset.update(json.load(file))\n",
    "\n",
    "dict_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schau dir die Daten an, wie viele Dialoge sind im Datensatz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of dialogs: {len(dict_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es handelt sich um einen multilingualen Datensatz, in welchem die jeweiligen Äußerungen in Source und Target mit unterschiedlicher Sprache gemischt sind. Lasst uns den Datensatz etwas umformen, so dass wir ihn für die weitere Verarbeitung praktisch in einem Pandas Dataframe vorliegen haben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_list = []\n",
    "for dialogID, dialog_steps in dict_dataset.items():\n",
    "    for step in dialog_steps:\n",
    "        dict1 = {\n",
    "            'dialogID': dialogID, \n",
    "            'utteranceID': step['utteranceID'],\n",
    "            'speaker': step['speaker'],\n",
    "            'de': step['source'] if step['speaker'] == 'customer' else step['target'],\n",
    "            'en': step['target'] if step['speaker'] == 'customer' else step['source']\n",
    "        }\n",
    "        utterance_list.append(dict1)\n",
    "\n",
    "# to flatten the data we create a list of dicts for each row and add this list en-bloc to the pandas dataframe. Using the append or concat function of pandas might work but is very inefficient as the data is copied for each call. \n",
    "df = pd.DataFrame(utterance_list)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Datensatz sind nun jedoch nicht nur Pizza Dialoge. Füge eine Spalte ```pizza_domain``` hinzu, die klassifiziert ob die jeweilige Äußerung das Wort ```Pizza``` enthält. Wenn dem so ist soll der Wert ```True``` sein, ansonsten ```False```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a column if the dialog step contains the word pizza or Pizza\n",
    "df['pizza_domain'] = df['de'].apply(lambda x: 'pizza' in x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können davon ausgehen, dass sofern eine Äußerung das Wort Pizza enthält der gesamte Dialog in der Domäne ist. Schreibe Python Code, der dir alle DialogIDs mit Pizza Service Dialogen ausgibt. \n",
    "\n",
    "Tipp: drop_duplicates() könnte hilfreich sein ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_ids_pizza_domain = list(df[df['pizza_domain']]['dialogID'].drop_duplicates())\n",
    "dialog_ids_pizza_domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und damit haben wir den Datensatz entsprechend aufbereitet, so dass wir damit einen Eindruck für unseren Pizza Dialog bekommen können. Wir können nun auf jeden Dialog folgendermaßen zugreifen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['dialogID'] == dialog_ids_pizza_domain[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schaue dir nun 3-5 verschiedene Dialoge an. Identifiziere Äußerungen die folgende Dialogeigenschaften enthalten:\n",
    "- implizite Verifikation \n",
    "- explizite Verifikation\n",
    "- anaphorische Referenz\n",
    "- Missverständnis\n",
    "- Nichtverständnis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
