{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation von DialogSystemen\n",
    "\n",
    "Ziele der heutigen Übung:\n",
    "- Verschiedene quantitative Metriken eines Dialogdatensatzes berechnen\n",
    "- Audio Files mittels verschiedenen Spracherkennern erkennen evaluieren\n",
    "\n",
    "Wir arbeiten heute mit dem Datensatz der DSTC3. Die Daten sind auf folgendem Repository zu finden:\n",
    "\n",
    "https://github.com/matthen/dstc?tab=readme-ov-file \n",
    "\n",
    "Lade dort die Dateien ```audio_*.tar.gz/audio_Apr11_S2.tar.gz``` und ```dstc3_test.tar.gz``` runter und entpacke diese. Wir betrachten nur Files der Unterordner Apr11_S2. Im dstc3_test findet ihr jeweils ein ```label.json``` welches den Dialog und die Transkriptionen enthält, in dem anderen Ordner findet ihr die Audiofiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladet euch zuerst die Dialogdateien aus dem label.json in eine Liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_FOLDER_DIALOG = \"../data/DSTC/dstc3_test/data/Apr11_S2\"\n",
    "DATASET_FOLDER_AUDIO = \"../data/DSTC/data/Apr11_S2\"\n",
    "\n",
    "dialog_list = []\n",
    "for dialog_dir in os.listdir(DATASET_FOLDER_DIALOG):\n",
    "    if \".DS_Store\" in dialog_dir:\n",
    "        continue\n",
    "    with open(os.path.join(DATASET_FOLDER_DIALOG, dialog_dir, \"label.json\"), encoding=\"utf-8\") as file:\n",
    "        dialog_list.append(json.load(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nutzerfragebogen\n",
    "\n",
    "Zum Ende des Tests wurde den Personen ein Fragebogen gestellt, Liste alle Fragen und die zugehörigen Antworten auf. Werte anschließen die Zufriedenheit der Versuchspersonen als Mittelwert aus. \n",
    "\n",
    "Hinweis: bei realen Datensätzen müssen wir immer damit rechnen, dass manche Werte nicht existieren. Überprüfe daher, ob die jeweiligen Einträge im dict auch enthalten sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback(dialog):\n",
    "    if 'task-information' in dialog:\n",
    "        if 'feedback' in dialog['task-information']:\n",
    "            feedback = dialog['task-information']['feedback']\n",
    "            return feedback\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "for dialog in dialog_list:\n",
    "    feedback = get_feedback(dialog)\n",
    "    if feedback and 'questionnaire' in feedback:\n",
    "        for fb in feedback['questionnaire']:\n",
    "            questions.append(fb[0])\n",
    "            answers.append(fb[1])\n",
    "\n",
    "#remove duplicates\n",
    "print(\"Questions asked: \", list(set(questions)))\n",
    "print(\"Answers given: \", list(set(answers)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['strongly disagree', 'disagree', 'lightly disagree', 'slightly agree', 'agree', 'strongly agree']\n",
    "# [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "sum_answers = 0\n",
    "for answer in answers:\n",
    "    match answer:\n",
    "        case 'strongly disagree':\n",
    "            sum_answers += 0\n",
    "        case 'disagree':\n",
    "            sum_answers += 1\n",
    "        case 'lightly disagree':\n",
    "            sum_answers += 2\n",
    "        case 'slightly agree':\n",
    "            sum_answers += 3\n",
    "        case 'agree':\n",
    "            sum_answers += 4\n",
    "        case 'strongly agree':\n",
    "            sum_answers += 5\n",
    "\n",
    "print(\"Number of answers: \", len(answers))\n",
    "print(\"Average answer: : \", sum_answers / len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogmanager Metriken\n",
    "\n",
    "Berechne die folgenden Metriken des Dialogmanagers: \n",
    "- Durchschnittliche Anzahl Nutzeräußerungen\n",
    "- Task Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ_list = []\n",
    "sum_turns = 0\n",
    "for dialog in dialog_list:\n",
    "    feedback = get_feedback(dialog)\n",
    "    if 'success' in feedback:\n",
    "        succ_list.append(feedback['success'])\n",
    "    if 'turns' in dialog:\n",
    "        sum_turns += len(dialog['turns'])\n",
    "    \n",
    "print(\"Task completion rate: \", succ_list.count(True)/len(succ_list))\n",
    "print(\"Average number of user utterances: \", sum_turns/len(dialog_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR Metriken\n",
    "\n",
    "Wir haben Audio Files und die zugehörigen Transkriptionen im label.json. Nutze deine Implementierung mit Vosk, um den Text des jeweiligen Audio Files zu erkennen und vergleiche dies mit der Referenz. Daraus können wir nun die Word Error Rate berechnen. Mache dies erst für ein File und dann für mehrere - optimalerweise den Durchschnitt des gesamten Datensatzes, aber je nach CPU und Vosk Modell könnte das für alle etwas lange dauern ;-). Dann nehme einfach eine Teilmenge.\n",
    "\n",
    "Um die WER zu berechnen, kann man entweder den Algorithmus der Levenshtein-Distanz nutzen oder aber die Python Bibliothek https://pypi.org/project/jiwer/.  \n",
    "\n",
    "Vergleiche auch gerne ein kleines und ein großes Vosk Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import vosk\n",
    "import speech_recognition as sr\n",
    "\n",
    "def recognize_vosk(audio_data: any, recognizer: sr.Recognizer, language = 'en') -> any:\n",
    "    try:\n",
    "        audio_data = recognizer.record(audio_data) \n",
    "        text = recognizer.recognize_vosk(audio_data, language=language)\n",
    "        text_json = json.loads(text)\n",
    "        return text_json\n",
    "    except sr.RequestError:\n",
    "        print(\"[Vosk] Error: Could not access Google Web Speech API;\")\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"[Vosk] Sorry, I do not understand\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from jiwer import wer\n",
    "\n",
    "def calculate_WER(recognized: str, label: str) -> float:\n",
    "    w = wer(label, recognized)\n",
    "    print(f\"Cmp: \\t{recognized}\\n\\t{label}(label)\\n\\tWER: {w}\")\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "num_utterances = 0\n",
    "sum_wer = 0\n",
    "\n",
    "for dialog in dialog_list[:10]:\n",
    "    for turn in dialog['turns']:\n",
    "        file = os.path.join(DATASET_FOLDER_AUDIO, dialog['session-id'], 'original_dir', turn['audio-file'])\n",
    "        print(str(file))\n",
    "        if os.path.exists(file):\n",
    "            audio = sr.AudioFile(file)\n",
    "            with audio as source:\n",
    "                result = recognize_vosk(source, recognizer)\n",
    "                sum_wer += calculate_WER(result['text'], turn['transcription'])\n",
    "                num_utterances += 1\n",
    "                #results.append({'asr': result['text']})\n",
    "\n",
    "print(f\"Average word error rate: {sum_wer/num_utterances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
