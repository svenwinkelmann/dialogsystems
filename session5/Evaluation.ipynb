{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation von DialogSystemen\n",
    "\n",
    "Ziele der heutigen Übung:\n",
    "- Verschiedene quantitative Metriken eines Dialogdatensatzes berechnen\n",
    "- Audio Files mittels verschiedenen Spracherkennern erkennen evaluieren\n",
    "\n",
    "Wir arbeiten heute mit dem Datensatz der DSTC3. Die Daten sind auf folgendem Repository zu finden:\n",
    "\n",
    "https://github.com/matthen/dstc?tab=readme-ov-file \n",
    "\n",
    "Lade dort die Dateien ```audio_*.tar.gz/audio_Apr11_S2.tar.gz``` und ```dstc3_test.tar.gz``` runter und entpacke diese. Wir betrachten nur Files der Unterordner Apr11_S2. Im dstc3_test findet ihr jeweils ein ```label.json``` welches den Dialog und die Transkriptionen enthält, in dem anderen Ordner findet ihr die Audiofiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladet euch zuerst die Dialogdateien aus dem label.json in eine Liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dialog_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nutzerfragebogen\n",
    "\n",
    "Zum Ende des Tests wurde den Personen ein Fragebogen gestellt, Liste alle Fragen und die zugehörigen Antworten auf. Werte anschließen die Zufriedenheit der Versuchspersonen als Mittelwert aus. \n",
    "\n",
    "Hinweis: bei realen Datensätzen müssen wir immer damit rechnen, dass manche Werte nicht existieren. Überprüfe daher, ob die jeweiligen Einträge im dict auch enthalten sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "# Questions asked:  ['The system understood me well.']\n",
    "# Answers given:  ['agree', 'strongly agree', 'disagree', 'strongly disagree', 'lightly disagree', 'slightly agree']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "# Number of answers:  498\n",
    "# Average answer: :  3.7751004016064256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogmanager Metriken\n",
    "\n",
    "Berechne die folgenden Metriken des Dialogmanagers: \n",
    "- Durchschnittliche Anzahl Nutzeräußerungen\n",
    "- Task Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "# Task completion rate:  0.9076305220883534\n",
    "# Average number of user utterances:  7.230923694779117\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR Metriken\n",
    "\n",
    "Wir haben Audio Files und die zugehörigen Transkriptionen im label.json. Nutze deine Implementierung mit Vosk, um den Text des jeweiligen Audio Files zu erkennen und vergleiche dies mit der Referenz. Daraus können wir nun die Word Error Rate berechnen. Mache dies erst für ein File und dann für mehrere - optimalerweise den Durchschnitt des gesamten Datensatzes, aber je nach CPU und Vosk Modell könnte das für alle etwas lange dauern ;-). Dann nehme einfach eine Teilmenge.\n",
    "\n",
    "Vergleiche auch gerne ein kleines und ein großes Vosk Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
